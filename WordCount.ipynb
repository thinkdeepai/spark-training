{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordCount.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thinkdeepai/spark-training/blob/main/WordCount.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KF5BK9NDeF0",
        "outputId": "2721e507-dfea-48b9-d90a-3e225de6d9ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# download and install dependencies\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: spark-3.1.2-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj1kA-7ADfly"
      },
      "source": [
        "import os\n",
        "\n",
        "# set the environment variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d5px-tHDjjo"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "batqH1d6FRAl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "75439c67-9efb-421d-bfac-c8e5c6e6c3ea"
      },
      "source": [
        "# verify the availability of Spark v3.1.2\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://15cee435a977:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fdd215be8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znyn6oMcFSTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da06320-306c-44c0-9e90-f9cf7ec91a48"
      },
      "source": [
        "# install ngrok to make your locally-hosted web server appear to be hosted on a subdomain of ngrok.com\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# tunnel Spark UI from a public URL to our application running locally\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-30 09:34:17--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.162.4.223, 52.73.79.40, 35.168.94.85, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.162.4.223|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.7’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  40.1MB/s    in 0.3s    \n",
            "\n",
            "2021-06-30 09:34:17 (40.1 MB/s) - ‘ngrok-stable-linux-amd64.zip.7’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "{\"tunnels\":[{\"name\":\"command_line (http)\",\"uri\":\"/api/tunnels/command_line%20%28http%29\",\"public_url\":\"http://b67ab0c88fc7.ngrok.io\",\"proto\":\"http\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":2,\"gauge\":0,\"rate1\":0.006040663754846687,\"rate5\":0.004737288342030325,\"rate15\":0.0019830183305383896,\"p50\":1351570,\"p90\":1624736,\"p95\":1624736,\"p99\":1624736},\"http\":{\"count\":2,\"rate1\":0.006040663754846687,\"rate5\":0.004737288342030325,\"rate15\":0.0019830183305383896,\"p50\":442461.5,\"p90\":497270,\"p95\":497270,\"p99\":497270}}},{\"name\":\"command_line\",\"uri\":\"/api/tunnels/command_line\",\"public_url\":\"https://b67ab0c88fc7.ngrok.io\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":3,\"gauge\":0,\"rate1\":0.016716732344572625,\"rate5\":0.007994228189591213,\"rate15\":0.0030928654785066186,\"p50\":934136,\"p90\":1204391,\"p95\":1204391,\"p99\":1204391},\"http\":{\"count\":3,\"rate1\":0.016716732344572625,\"rate5\":0.007994228189591213,\"rate15\":0.0030928654785066186,\"p50\":308156,\"p90\":496866,\"p95\":496866,\"p99\":496866}}}],\"uri\":\"/api/tunnels\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jngd94pHDkGU"
      },
      "source": [
        "# Read the input file and Calculating words count\n",
        "text_file = sc.textFile(\"test.txt\")\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
        "                            .map(lambda word: (word, 1)) \\\n",
        "                            .reduceByKey(lambda x, y: x + y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fYUuPMhDoju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8b53ac-59eb-438e-aaec-12bc6a13ec35"
      },
      "source": [
        "# Printing each word with its respective count\n",
        "output = counts.collect()\n",
        "for (word, count) in output:\n",
        "    print(\"%s: %i\" % (word, count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Duis: 1\n",
            "Excepteur: 1\n",
            "Lorem: 1\n",
            "Ut: 1\n",
            "ad: 1\n",
            "adipiscing: 1\n",
            "aliqua.: 1\n",
            "aliquip: 1\n",
            "amet,: 1\n",
            "anim: 1\n",
            "aute: 1\n",
            "cillum: 1\n",
            "commodo: 1\n",
            "consectetur: 1\n",
            "consequat.: 1\n",
            "culpa: 1\n",
            "cupidatat: 1\n",
            "deserunt: 1\n",
            "do: 1\n",
            "dolor: 2\n",
            "dolore: 2\n",
            "ea: 1\n",
            "eiusmod: 1\n",
            "elit,: 1\n",
            "enim: 1\n",
            "esse: 1\n",
            "est: 1\n",
            "et: 1\n",
            "eu: 1\n",
            "ex: 1\n",
            "exercitation: 1\n",
            "fugiat: 1\n",
            "id: 1\n",
            "in: 3\n",
            "incididunt: 1\n",
            "ipsum: 1\n",
            "irure: 1\n",
            "labore: 1\n",
            "laboris: 1\n",
            "laborum.: 1\n",
            "magna: 1\n",
            "minim: 1\n",
            "mollit: 1\n",
            "nisi: 1\n",
            "non: 1\n",
            "nostrud: 1\n",
            "nulla: 1\n",
            "occaecat: 1\n",
            "officia: 1\n",
            "pariatur.: 1\n",
            "proident,: 1\n",
            "qui: 1\n",
            "quis: 1\n",
            "reprehenderit: 1\n",
            "sed: 1\n",
            "sint: 1\n",
            "sit: 1\n",
            "sunt: 1\n",
            "tempor: 1\n",
            "ullamco: 1\n",
            "ut: 2\n",
            "velit: 1\n",
            "veniam,: 1\n",
            "voluptate: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfkE7qDDENL7"
      },
      "source": [
        "# Stopping Spark-Session and Spark context\n",
        "sc.stop()\n",
        "spark.stop()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}